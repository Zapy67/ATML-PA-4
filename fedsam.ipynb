{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61dd2525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ATML-PA-4' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b atm-10 http://github.com/Zapy67/ATML-PA-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bd9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: redirecting to https://github.com/Zapy67/ATML-PA-4/\n",
      "From http://github.com/Zapy67/ATML-PA-4\n",
      " * branch            HEAD       -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull -b atm-10 http://github.com/Zapy67/ATML-PA-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b14a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ATML-PA-4\n"
     ]
    }
   ],
   "source": [
    "%cd ATML-PA-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e5b63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ATML - PA 4.pdf'   fed_lib\t   LICENSE     task1.ipynb   task3.ipynb\n",
      " data\t\t    fedsam.ipynb   README.md   task2.ipynb   task4.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d89142",
   "metadata": {},
   "source": [
    "#  FedSAM on heterogeneous domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8077c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88a1391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fed_lib' from '/kaggle/working/ATML-PA-4/fed_lib/__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fed_lib\n",
    "import importlib\n",
    "importlib.reload(fed_lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31d14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fedlab\n",
      "  Downloading fedlab-1.3.0.tar.gz (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from fedlab) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from fedlab) (0.21.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fedlab) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fedlab) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from fedlab) (1.2.2)\n",
      "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from fedlab) (12.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fedlab) (4.67.1)\n",
      "Collecting munch (from fedlab)\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.1->fedlab)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->fedlab) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->fedlab) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.8.2->fedlab) (11.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->fedlab) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->fedlab) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->fedlab) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->fedlab) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->fedlab) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->fedlab) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->fedlab) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fedlab) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fedlab) (2025.2)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->fedlab) (12.575.51)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fedlab) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fedlab) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fedlab) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->fedlab) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->fedlab) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fedlab) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fedlab) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fedlab) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->fedlab) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->fedlab) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->fedlab) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Building wheels for collected packages: fedlab\n",
      "  Building wheel for fedlab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fedlab: filename=fedlab-1.3.0-py3-none-any.whl size=96033 sha256=1b0efbd8cbb0f115ba3ca3ea6650e1ee23f7dc4e06d85b3a685f7ddbf170e9c8\n",
      "  Stored in directory: /root/.cache/pip/wheels/14/c7/83/be3015bd51cbd66c4a444456870b8816d1f03db062be5540da\n",
      "Successfully built fedlab\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, fedlab\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fedlab-1.3.0 munch-4.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install fedlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d1ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:28:05 - numexpr.utils - INFO - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'fed_lib.fed_model' from '/kaggle/working/ATML-PA-4/fed_lib/fed_model.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fed_lib import fed_methods, fed_model, utils\n",
    "importlib.reload(utils)\n",
    "importlib.reload(fed_methods)\n",
    "importlib.reload(fed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910de48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae98846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = utils.get_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb3dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_loaders = utils.get_heterogenous_domains(trainset, clients=5, balance=False, min_require_size=20, alpha=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c781175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Label Distribution (P(Y)): [0.079 0.068 0.088 0.067 0.131 0.088 0.111 0.03  0.213 0.126]\n",
      "Entropy of Label Distribution H(P(Y)): 2.102870626465239\n",
      "Normalized Entropy of Label Distribution: 0.9132651092302875\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Label Distribution (P(Y)): [0.152 0.122 0.153 0.157 0.033 0.006 0.009 0.252 0.116]\n",
      "Entropy of Label Distribution H(P(Y)): 1.8258316532923375\n",
      "Normalized Entropy of Label Distribution: 0.8309717960218086\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Label Distribution (P(Y)): [0.115 0.05  0.04  0.011 0.081 0.052 0.12  0.1   0.103 0.328]\n",
      "Entropy of Label Distribution H(P(Y)): 1.927983508742169\n",
      "Normalized Entropy of Label Distribution: 0.8373125990471938\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Label Distribution (P(Y)): [0.1   0.042 0.08  0.191 0.165 0.204 0.219]\n",
      "Entropy of Label Distribution H(P(Y)): 1.768351768347601\n",
      "Normalized Entropy of Label Distribution: 0.9087530424804496\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Label Distribution (P(Y)): [0.049 0.222 0.128 0.052 0.089 0.156 0.044 0.113 0.056 0.091]\n",
      "Entropy of Label Distribution H(P(Y)): 2.073209740959855\n",
      "Normalized Entropy of Label Distribution: 0.9003835503269351\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, loader in enumerate(client_loaders):\n",
    "    utils.calculate_label_skew(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b76429",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_weights = [len(client.dataset.indices)/len(trainset.dataset) for client in client_loaders]\n",
    "domains = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d723a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2187, 0.22118, 0.17032, 0.20554, 0.18426]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a6027db",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = \"dirichlet\"\n",
    "alpha = 0.1\n",
    "num_clients = 5\n",
    "domains=None\n",
    "fed = fed_model.Federation(num_clients, None, partition, domains, alpha, device, batch_size=64, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8845dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_loaders = fed.client_dataloaders\n",
    "client_weights = [len(client.dataset.indices)/len(trainset.dataset) for client in client_loaders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07bf9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed.set_method(fed_methods.FedSAM(sam_rho=0, \n",
    "             num_local_steps=len(trainset)/num_clients, \n",
    "             client_aggregation_weights= client_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7b28990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.1824, -0.0630,  0.0254],\n",
       "           [ 0.1401, -0.0197, -0.0389],\n",
       "           [ 0.0319, -0.0982, -0.0596]],\n",
       " \n",
       "          [[-0.1564, -0.0116,  0.1150],\n",
       "           [ 0.1410,  0.0897, -0.0470],\n",
       "           [-0.0430, -0.0646, -0.0287]],\n",
       " \n",
       "          [[-0.1313, -0.1540,  0.1704],\n",
       "           [-0.1034,  0.1507,  0.1167],\n",
       "           [-0.0448, -0.0309,  0.1785]]],\n",
       " \n",
       " \n",
       "         [[[-0.1328, -0.1646,  0.0543],\n",
       "           [-0.1545,  0.0200, -0.0040],\n",
       "           [-0.0724,  0.0293, -0.1763]],\n",
       " \n",
       "          [[-0.0928,  0.1116,  0.0440],\n",
       "           [-0.1544,  0.1698,  0.1616],\n",
       "           [-0.0544, -0.0817, -0.0476]],\n",
       " \n",
       "          [[ 0.1456, -0.1223,  0.1681],\n",
       "           [ 0.0542, -0.1107, -0.0337],\n",
       "           [-0.0403, -0.1178,  0.0614]]],\n",
       " \n",
       " \n",
       "         [[[-0.0321,  0.1250, -0.0090],\n",
       "           [ 0.0181, -0.0425, -0.1068],\n",
       "           [ 0.0123, -0.0468,  0.0771]],\n",
       " \n",
       "          [[ 0.0348,  0.0894,  0.0949],\n",
       "           [ 0.0702,  0.1732,  0.0368],\n",
       "           [ 0.1065, -0.0481,  0.0994]],\n",
       " \n",
       "          [[ 0.0962,  0.0695,  0.0545],\n",
       "           [-0.0942, -0.1420, -0.1824],\n",
       "           [ 0.0415, -0.0801, -0.0979]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0373, -0.0180, -0.1500],\n",
       "           [ 0.0914, -0.0969, -0.0903],\n",
       "           [ 0.0461, -0.0394,  0.1099]],\n",
       " \n",
       "          [[-0.0220,  0.0445,  0.1889],\n",
       "           [-0.1082,  0.0715,  0.0668],\n",
       "           [-0.1297, -0.0987,  0.0503]],\n",
       " \n",
       "          [[-0.0655,  0.1328, -0.0206],\n",
       "           [-0.1265, -0.1288, -0.1581],\n",
       "           [ 0.1807,  0.0299, -0.1402]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1823,  0.1337,  0.0330],\n",
       "           [ 0.1331, -0.1433,  0.1150],\n",
       "           [ 0.0540,  0.1089, -0.1094]],\n",
       " \n",
       "          [[-0.0257, -0.1016,  0.0951],\n",
       "           [ 0.0456,  0.1174,  0.0025],\n",
       "           [-0.0366, -0.1312,  0.0178]],\n",
       " \n",
       "          [[ 0.0451, -0.0568,  0.1279],\n",
       "           [ 0.1159, -0.1609, -0.1553],\n",
       "           [ 0.0472, -0.0124, -0.1860]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1442, -0.1605,  0.0626],\n",
       "           [-0.0594,  0.0075,  0.0128],\n",
       "           [ 0.0437,  0.1258,  0.0613]],\n",
       " \n",
       "          [[-0.0375, -0.1184,  0.0091],\n",
       "           [-0.1476,  0.0140,  0.0595],\n",
       "           [ 0.1119, -0.1178,  0.1091]],\n",
       " \n",
       "          [[ 0.1003,  0.1611, -0.0946],\n",
       "           [-0.1327,  0.1170, -0.1444],\n",
       "           [-0.1750, -0.0856, -0.0723]]],\n",
       " \n",
       " \n",
       "         [[[-0.0183, -0.1689, -0.1847],\n",
       "           [ 0.0666, -0.0889,  0.0268],\n",
       "           [ 0.0065,  0.0083, -0.1433]],\n",
       " \n",
       "          [[ 0.1247,  0.0175,  0.0096],\n",
       "           [ 0.1324, -0.0355,  0.0048],\n",
       "           [-0.1320, -0.1644, -0.1292]],\n",
       " \n",
       "          [[-0.0170, -0.0781,  0.1636],\n",
       "           [ 0.0273,  0.1155,  0.0469],\n",
       "           [-0.1616,  0.0405, -0.1730]]],\n",
       " \n",
       " \n",
       "         [[[-0.0830,  0.1450, -0.0422],\n",
       "           [ 0.0084,  0.0866,  0.1087],\n",
       "           [-0.1711, -0.0633,  0.1055]],\n",
       " \n",
       "          [[-0.0666,  0.0621,  0.0052],\n",
       "           [-0.0971,  0.0235,  0.0646],\n",
       "           [ 0.1095, -0.1668,  0.1147]],\n",
       " \n",
       "          [[ 0.0597, -0.0249,  0.0880],\n",
       "           [ 0.1432,  0.0679,  0.0591],\n",
       "           [ 0.0150, -0.1648, -0.0884]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0821, -0.0770,  0.1060],\n",
       "           [ 0.0721,  0.1444, -0.1077],\n",
       "           [-0.1756, -0.1285, -0.0873]],\n",
       " \n",
       "          [[-0.1540,  0.0468, -0.0725],\n",
       "           [ 0.1325,  0.1909, -0.0157],\n",
       "           [-0.1403,  0.1874, -0.1183]],\n",
       " \n",
       "          [[ 0.1691, -0.1378, -0.0751],\n",
       "           [ 0.0231,  0.1738,  0.1809],\n",
       "           [ 0.0333,  0.1097,  0.0484]]],\n",
       " \n",
       " \n",
       "         [[[-0.0186, -0.0372,  0.1486],\n",
       "           [-0.1588, -0.0910, -0.0664],\n",
       "           [ 0.0534, -0.0955,  0.0905]],\n",
       " \n",
       "          [[ 0.1580, -0.1731, -0.0762],\n",
       "           [-0.1924, -0.0466, -0.1325],\n",
       "           [ 0.0389,  0.0188,  0.0718]],\n",
       " \n",
       "          [[-0.0392, -0.0432,  0.0947],\n",
       "           [-0.0003, -0.1210,  0.0247],\n",
       "           [ 0.1278,  0.1905,  0.1751]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1628, -0.1794, -0.0663],\n",
       "           [-0.1373, -0.1066,  0.0425],\n",
       "           [-0.0157,  0.0795,  0.1004]],\n",
       " \n",
       "          [[-0.1500, -0.1858,  0.1820],\n",
       "           [-0.1149, -0.0399,  0.0546],\n",
       "           [ 0.0273, -0.1636,  0.0772]],\n",
       " \n",
       "          [[ 0.0402,  0.1817, -0.0090],\n",
       "           [ 0.1066, -0.0725, -0.0402],\n",
       "           [-0.1612, -0.1613, -0.0149]]],\n",
       " \n",
       " \n",
       "         [[[-0.1368,  0.0529,  0.1337],\n",
       "           [ 0.1019, -0.1476,  0.1374],\n",
       "           [ 0.1711, -0.1242, -0.1500]],\n",
       " \n",
       "          [[ 0.1371, -0.0415, -0.1457],\n",
       "           [ 0.0451, -0.0311,  0.0273],\n",
       "           [ 0.1308, -0.0440, -0.1195]],\n",
       " \n",
       "          [[ 0.0767, -0.0666, -0.1219],\n",
       "           [-0.1825,  0.0275,  0.0160],\n",
       "           [ 0.0171,  0.1208,  0.0608]]],\n",
       " \n",
       " \n",
       "         [[[-0.0159,  0.1517, -0.0566],\n",
       "           [ 0.1800, -0.1866, -0.0504],\n",
       "           [-0.0494, -0.1398, -0.1592]],\n",
       " \n",
       "          [[ 0.1688,  0.0487,  0.0245],\n",
       "           [-0.0448, -0.1598, -0.1624],\n",
       "           [ 0.0117, -0.0911, -0.0399]],\n",
       " \n",
       "          [[ 0.0055, -0.0848,  0.0956],\n",
       "           [-0.0733,  0.1443, -0.0240],\n",
       "           [ 0.1406, -0.0781, -0.0850]]],\n",
       " \n",
       " \n",
       "         [[[-0.0292, -0.0254,  0.1272],\n",
       "           [-0.1504,  0.1229, -0.0670],\n",
       "           [ 0.1144, -0.0879,  0.1430]],\n",
       " \n",
       "          [[-0.0643, -0.0800,  0.1435],\n",
       "           [-0.0864, -0.1376,  0.0879],\n",
       "           [-0.1802, -0.1619,  0.1238]],\n",
       " \n",
       "          [[ 0.1781,  0.0132,  0.0358],\n",
       "           [-0.1796,  0.1464,  0.0888],\n",
       "           [ 0.0772,  0.1680, -0.0204]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0370,  0.1489,  0.0809],\n",
       "           [ 0.1228, -0.0819,  0.1735],\n",
       "           [-0.0783,  0.1864, -0.1082]],\n",
       " \n",
       "          [[ 0.0516, -0.1583,  0.1695],\n",
       "           [ 0.1450, -0.1018,  0.0416],\n",
       "           [-0.1269, -0.1153, -0.0653]],\n",
       " \n",
       "          [[ 0.0883,  0.1267, -0.0773],\n",
       "           [ 0.0952, -0.0730,  0.0063],\n",
       "           [-0.0253,  0.1291, -0.0039]]],\n",
       " \n",
       " \n",
       "         [[[-0.1678, -0.0488, -0.0691],\n",
       "           [ 0.1350,  0.0949, -0.0766],\n",
       "           [-0.1663,  0.0376, -0.0312]],\n",
       " \n",
       "          [[-0.0574,  0.0173,  0.1555],\n",
       "           [-0.0061,  0.0085,  0.0922],\n",
       "           [ 0.1671, -0.0854, -0.1335]],\n",
       " \n",
       "          [[ 0.1557,  0.1266,  0.1539],\n",
       "           [-0.0679, -0.0761,  0.0607],\n",
       "           [-0.1079,  0.1360, -0.1540]]],\n",
       " \n",
       " \n",
       "         [[[-0.1735,  0.1444, -0.1437],\n",
       "           [-0.0371,  0.0878, -0.1008],\n",
       "           [ 0.1673,  0.1862,  0.1051]],\n",
       " \n",
       "          [[-0.0305,  0.1569, -0.1620],\n",
       "           [-0.0021, -0.0950,  0.1279],\n",
       "           [ 0.0357, -0.1585,  0.1788]],\n",
       " \n",
       "          [[ 0.0268,  0.1196,  0.1279],\n",
       "           [ 0.1669, -0.0971, -0.0477],\n",
       "           [ 0.1866,  0.0988, -0.0412]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0329, -0.1579,  0.1052],\n",
       "           [ 0.1087, -0.1414,  0.0163],\n",
       "           [-0.1292, -0.1841, -0.1770]],\n",
       " \n",
       "          [[-0.1779,  0.0207,  0.0367],\n",
       "           [-0.0489,  0.1086, -0.0084],\n",
       "           [-0.1016, -0.0960, -0.1871]],\n",
       " \n",
       "          [[ 0.0078,  0.0396, -0.1865],\n",
       "           [ 0.1360,  0.0368, -0.1025],\n",
       "           [-0.1237,  0.1361,  0.0464]]],\n",
       " \n",
       " \n",
       "         [[[-0.1354,  0.1193,  0.0179],\n",
       "           [-0.0846,  0.0926, -0.1806],\n",
       "           [ 0.0709, -0.1757,  0.1612]],\n",
       " \n",
       "          [[ 0.1453, -0.1796, -0.0839],\n",
       "           [ 0.1580, -0.1891, -0.0687],\n",
       "           [ 0.1698,  0.1784, -0.0158]],\n",
       " \n",
       "          [[ 0.0351, -0.0667, -0.0275],\n",
       "           [ 0.0822, -0.0011,  0.1574],\n",
       "           [-0.0928, -0.0657, -0.1900]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0173,  0.1118,  0.1387],\n",
       "           [-0.1680, -0.0833,  0.1242],\n",
       "           [-0.1569,  0.1258,  0.0250]],\n",
       " \n",
       "          [[-0.0854,  0.1296, -0.0852],\n",
       "           [-0.0309, -0.1317,  0.0373],\n",
       "           [ 0.0306,  0.0366, -0.0319]],\n",
       " \n",
       "          [[ 0.1232, -0.0248, -0.1259],\n",
       "           [-0.1511, -0.0678, -0.1908],\n",
       "           [-0.0388,  0.1649,  0.0823]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0346,  0.0981,  0.0127],\n",
       "           [ 0.0460,  0.0640,  0.1218],\n",
       "           [ 0.0307, -0.1064,  0.0865]],\n",
       " \n",
       "          [[ 0.0683, -0.1372, -0.1660],\n",
       "           [ 0.0617, -0.1733, -0.1343],\n",
       "           [ 0.1717,  0.0437, -0.0050]],\n",
       " \n",
       "          [[-0.0244, -0.0615,  0.0653],\n",
       "           [ 0.0950, -0.1106,  0.1491],\n",
       "           [-0.0580, -0.0505, -0.0643]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0953,  0.1583,  0.1580],\n",
       "           [-0.1047,  0.1383, -0.1149],\n",
       "           [ 0.1064, -0.0464,  0.0196]],\n",
       " \n",
       "          [[ 0.0620,  0.1756,  0.1383],\n",
       "           [ 0.0894, -0.1557, -0.1088],\n",
       "           [ 0.1197,  0.1148, -0.0833]],\n",
       " \n",
       "          [[-0.0694, -0.0686, -0.1210],\n",
       "           [-0.0508, -0.0035, -0.1477],\n",
       "           [-0.0994,  0.0956,  0.0486]]],\n",
       " \n",
       " \n",
       "         [[[-0.0624,  0.1331,  0.1449],\n",
       "           [ 0.0431,  0.0088,  0.0367],\n",
       "           [-0.0766, -0.0397,  0.0204]],\n",
       " \n",
       "          [[ 0.0705, -0.1277, -0.1194],\n",
       "           [-0.1316,  0.1762,  0.0298],\n",
       "           [-0.1371,  0.1584,  0.0933]],\n",
       " \n",
       "          [[-0.1426, -0.0863, -0.1134],\n",
       "           [-0.1524, -0.1456, -0.1533],\n",
       "           [-0.1299, -0.0861, -0.1712]]],\n",
       " \n",
       " \n",
       "         [[[-0.1913,  0.0493,  0.1250],\n",
       "           [ 0.0798,  0.1420,  0.0341],\n",
       "           [ 0.1212,  0.1152, -0.1709]],\n",
       " \n",
       "          [[-0.1263,  0.1224, -0.0228],\n",
       "           [-0.1782, -0.1742,  0.1580],\n",
       "           [-0.0781,  0.0915,  0.1822]],\n",
       " \n",
       "          [[-0.0915, -0.1508, -0.1754],\n",
       "           [-0.1058,  0.1787, -0.0536],\n",
       "           [-0.0261, -0.0800,  0.1378]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0712,  0.1408,  0.1750],\n",
       "           [ 0.1324, -0.0917, -0.0787],\n",
       "           [-0.1582, -0.1696, -0.1694]],\n",
       " \n",
       "          [[ 0.1213, -0.1719, -0.0500],\n",
       "           [ 0.1318,  0.1569, -0.1560],\n",
       "           [-0.1779, -0.0887,  0.1143]],\n",
       " \n",
       "          [[ 0.0610, -0.0321,  0.1051],\n",
       "           [ 0.1297,  0.1773,  0.1437],\n",
       "           [ 0.0811,  0.1149, -0.1075]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0578, -0.1793,  0.0503],\n",
       "           [-0.1068,  0.0527, -0.0761],\n",
       "           [-0.0263,  0.0120,  0.1655]],\n",
       " \n",
       "          [[ 0.0681,  0.0447,  0.1226],\n",
       "           [-0.1364,  0.0596,  0.0004],\n",
       "           [-0.1517, -0.0771, -0.0513]],\n",
       " \n",
       "          [[-0.0137, -0.1473, -0.1848],\n",
       "           [ 0.1846,  0.1769,  0.0777],\n",
       "           [ 0.1891, -0.0312, -0.0887]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0516,  0.0094,  0.1189],\n",
       "           [-0.1718,  0.0320,  0.1669],\n",
       "           [-0.1674,  0.1120, -0.0554]],\n",
       " \n",
       "          [[-0.0010,  0.0282, -0.1816],\n",
       "           [ 0.1156,  0.1240,  0.1339],\n",
       "           [-0.0915, -0.1435,  0.0714]],\n",
       " \n",
       "          [[ 0.0384,  0.1147, -0.0171],\n",
       "           [ 0.0441, -0.0734, -0.0601],\n",
       "           [ 0.0073,  0.1736,  0.0123]]],\n",
       " \n",
       " \n",
       "         [[[-0.1897, -0.1721, -0.0185],\n",
       "           [ 0.1174, -0.1473, -0.1021],\n",
       "           [ 0.0171, -0.1619,  0.1548]],\n",
       " \n",
       "          [[-0.1541, -0.0997, -0.0801],\n",
       "           [ 0.1448,  0.0709, -0.1103],\n",
       "           [-0.0643, -0.1748, -0.1349]],\n",
       " \n",
       "          [[-0.0152,  0.1695,  0.1229],\n",
       "           [ 0.0652,  0.0269,  0.0654],\n",
       "           [-0.1301,  0.0914, -0.0568]]],\n",
       " \n",
       " \n",
       "         [[[-0.0388,  0.0526,  0.1416],\n",
       "           [ 0.0368,  0.0136, -0.1166],\n",
       "           [-0.1666,  0.1840, -0.0138]],\n",
       " \n",
       "          [[ 0.0528,  0.0074, -0.0585],\n",
       "           [ 0.0356,  0.0046,  0.0315],\n",
       "           [ 0.1497, -0.0898, -0.0487]],\n",
       " \n",
       "          [[ 0.1906, -0.1735,  0.1476],\n",
       "           [-0.1597, -0.1305, -0.1399],\n",
       "           [-0.0718, -0.0655,  0.0109]]],\n",
       " \n",
       " \n",
       "         [[[-0.0972,  0.0656, -0.1178],\n",
       "           [ 0.0814,  0.1189,  0.0592],\n",
       "           [ 0.0300,  0.0588,  0.0899]],\n",
       " \n",
       "          [[-0.0847,  0.0585, -0.0209],\n",
       "           [ 0.1220,  0.1559, -0.1840],\n",
       "           [-0.0418,  0.1292,  0.1481]],\n",
       " \n",
       "          [[ 0.1181,  0.1383, -0.0729],\n",
       "           [-0.1821,  0.1803, -0.0246],\n",
       "           [-0.1532, -0.1754,  0.1400]]],\n",
       " \n",
       " \n",
       "         [[[-0.1618, -0.0118, -0.1117],\n",
       "           [-0.0580, -0.1598, -0.1319],\n",
       "           [-0.0786, -0.1168, -0.0683]],\n",
       " \n",
       "          [[ 0.0033,  0.1664,  0.1717],\n",
       "           [-0.1776,  0.0127, -0.0168],\n",
       "           [-0.1715, -0.1299,  0.0310]],\n",
       " \n",
       "          [[ 0.1421,  0.1064,  0.1223],\n",
       "           [ 0.0391, -0.1754,  0.1675],\n",
       "           [-0.0356,  0.1224,  0.1843]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1588,  0.0414,  0.1145],\n",
       "           [ 0.0686, -0.1236, -0.0352],\n",
       "           [ 0.0328,  0.0271, -0.1723]],\n",
       " \n",
       "          [[-0.0472, -0.0067,  0.1754],\n",
       "           [ 0.0149,  0.1485, -0.0244],\n",
       "           [-0.1468,  0.0438,  0.1108]],\n",
       " \n",
       "          [[-0.0838,  0.0876, -0.0436],\n",
       "           [-0.1436,  0.1483, -0.0061],\n",
       "           [-0.0620,  0.1426,  0.1167]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0818,  0.1449, -0.1363,  0.0525, -0.0157,  0.1138,  0.0208, -0.0594,\n",
       "         -0.1007, -0.0799, -0.0043, -0.1106,  0.0329,  0.1269,  0.1494, -0.1801,\n",
       "          0.1488, -0.0642, -0.0245,  0.1789, -0.1101,  0.1095,  0.0643, -0.0152,\n",
       "          0.0430,  0.0018, -0.1550,  0.0446,  0.0252, -0.1831, -0.1705, -0.1458],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-3.3552e-02,  2.7354e-02, -3.9258e-02],\n",
       "           [-2.6454e-02,  4.7095e-02, -4.7928e-02],\n",
       "           [ 4.4067e-02, -4.7866e-02,  3.8072e-02]],\n",
       " \n",
       "          [[ 7.6091e-03,  2.4763e-02,  3.8643e-02],\n",
       "           [-4.3174e-02, -8.0694e-03,  3.7207e-03],\n",
       "           [ 3.2605e-02,  1.6279e-02,  1.2623e-02]],\n",
       " \n",
       "          [[-4.3129e-02, -3.0368e-02, -2.4665e-02],\n",
       "           [ 3.7530e-02,  5.2980e-02, -4.3065e-02],\n",
       "           [ 5.8663e-02, -4.6473e-02, -9.3805e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4234e-02,  2.6481e-04, -4.1509e-02],\n",
       "           [-2.5612e-02, -5.5389e-03,  3.9250e-02],\n",
       "           [-4.1816e-02,  7.7833e-03,  8.7026e-03]],\n",
       " \n",
       "          [[-1.5566e-03, -4.0942e-02, -1.6330e-02],\n",
       "           [ 2.1055e-03, -4.8245e-02, -2.2341e-02],\n",
       "           [ 1.8774e-02,  1.6980e-02, -2.5920e-02]],\n",
       " \n",
       "          [[ 5.2974e-02,  4.1508e-02, -3.9427e-02],\n",
       "           [ 4.1193e-02, -1.7988e-02,  3.1040e-02],\n",
       "           [ 1.9973e-02,  5.1430e-02, -2.1150e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.3867e-02, -4.1571e-02,  1.0697e-02],\n",
       "           [ 3.6033e-02,  1.8383e-02, -5.6382e-02],\n",
       "           [ 7.8218e-03,  5.7581e-02,  4.0367e-03]],\n",
       " \n",
       "          [[-1.9730e-02, -4.2382e-02,  3.9550e-03],\n",
       "           [-4.0477e-03,  2.6924e-02,  1.5993e-02],\n",
       "           [ 2.9930e-02, -1.7850e-02,  1.8104e-02]],\n",
       " \n",
       "          [[-3.4956e-02, -2.9154e-02, -2.5876e-02],\n",
       "           [ 3.0840e-02, -9.1987e-04, -4.1370e-02],\n",
       "           [ 3.8200e-03, -4.4272e-02, -3.1124e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.4292e-02,  5.3895e-02, -3.2561e-02],\n",
       "           [ 4.4369e-02, -5.8916e-02,  5.6858e-02],\n",
       "           [-5.1861e-02,  2.7171e-02,  4.5947e-02]],\n",
       " \n",
       "          [[-3.1655e-02, -2.2684e-02, -5.3064e-02],\n",
       "           [ 5.3710e-03,  4.2146e-02, -1.4275e-02],\n",
       "           [ 7.9174e-03, -1.0805e-02, -9.5490e-03]],\n",
       " \n",
       "          [[-3.1520e-03, -3.3916e-02,  5.8861e-02],\n",
       "           [ 4.2554e-02, -3.3027e-02,  4.0991e-02],\n",
       "           [ 1.1309e-02, -5.5451e-05, -1.2816e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 6.2888e-03,  4.5281e-02, -2.4204e-02],\n",
       "           [-3.7387e-03, -1.1166e-02, -5.7847e-02],\n",
       "           [ 5.8809e-02, -4.2283e-02, -5.2265e-02]],\n",
       " \n",
       "          [[ 4.5669e-02, -3.7019e-02, -2.1327e-02],\n",
       "           [-5.1142e-02, -3.1513e-02,  3.4062e-02],\n",
       "           [ 2.7727e-02, -5.3950e-02, -3.5858e-02]],\n",
       " \n",
       "          [[-1.1651e-02,  1.7225e-03,  3.5761e-02],\n",
       "           [ 5.5610e-02,  1.6164e-02,  4.9726e-02],\n",
       "           [-4.5026e-02,  4.8014e-02,  7.7622e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.4902e-02,  2.8150e-02,  1.4406e-02],\n",
       "           [-3.9440e-02,  5.4683e-03, -2.6412e-02],\n",
       "           [-5.3399e-02, -3.8030e-04, -3.8268e-02]],\n",
       " \n",
       "          [[-2.1580e-02, -5.1252e-02,  5.4302e-02],\n",
       "           [ 1.4363e-02,  5.8705e-02, -4.0128e-02],\n",
       "           [ 4.2360e-03,  5.6497e-02, -1.0623e-02]],\n",
       " \n",
       "          [[-5.0617e-02, -4.5751e-02,  3.7140e-02],\n",
       "           [-4.0629e-02,  3.0569e-02, -3.8734e-02],\n",
       "           [-3.0995e-02, -4.2325e-02, -5.6016e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-4.3214e-02, -2.3537e-02, -7.8168e-03],\n",
       "           [-5.8675e-02, -1.0863e-02, -1.4154e-02],\n",
       "           [ 2.8967e-02,  3.1843e-03, -3.1614e-02]],\n",
       " \n",
       "          [[-7.9889e-05, -1.7894e-02, -2.4225e-03],\n",
       "           [ 1.9196e-02, -2.9369e-02,  4.9220e-02],\n",
       "           [-5.6359e-02, -3.8597e-02, -5.7126e-02]],\n",
       " \n",
       "          [[ 5.5228e-02,  5.6958e-02, -5.7313e-03],\n",
       "           [ 3.0351e-02,  1.4879e-03,  2.1602e-02],\n",
       "           [-4.1451e-02, -3.5744e-02, -2.0586e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8823e-02, -5.0054e-03, -1.1796e-02],\n",
       "           [-1.5226e-02, -3.0930e-02, -4.4667e-02],\n",
       "           [-1.4961e-02, -3.1785e-02,  1.3549e-02]],\n",
       " \n",
       "          [[-1.4913e-02, -2.0176e-02,  2.8000e-02],\n",
       "           [ 5.3889e-02, -5.8624e-02,  1.8477e-02],\n",
       "           [ 3.1277e-02, -4.0826e-02,  3.6634e-02]],\n",
       " \n",
       "          [[ 9.8987e-03,  4.8993e-02,  1.5516e-02],\n",
       "           [-2.1703e-02,  5.4597e-02,  4.1435e-02],\n",
       "           [-3.8989e-02, -2.3829e-03, -1.7450e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.3585e-02, -7.5484e-03,  1.0033e-02],\n",
       "           [ 1.0900e-02, -8.6996e-03, -2.2095e-02],\n",
       "           [-1.7307e-02,  3.1789e-03, -5.7152e-02]],\n",
       " \n",
       "          [[ 9.0200e-03,  3.1033e-02, -5.8368e-02],\n",
       "           [-5.2452e-02, -3.8188e-03, -1.9877e-02],\n",
       "           [-2.3608e-02,  8.5487e-03,  1.0807e-02]],\n",
       " \n",
       "          [[-2.3762e-02, -3.6885e-02,  1.8972e-02],\n",
       "           [ 5.7212e-03, -4.4805e-02, -3.4313e-02],\n",
       "           [ 1.1245e-02, -4.9930e-02,  1.9688e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4226e-02, -8.5275e-04, -1.1031e-02],\n",
       "           [ 2.0155e-02,  2.6633e-02, -4.6897e-02],\n",
       "           [ 4.7638e-02, -4.0821e-02,  2.4329e-02]],\n",
       " \n",
       "          [[ 1.5643e-02,  5.6021e-02,  5.7112e-02],\n",
       "           [-2.4882e-02, -6.0500e-03, -9.4287e-03],\n",
       "           [-2.5527e-02, -6.2021e-03, -1.7491e-06]],\n",
       " \n",
       "          [[-4.5079e-02,  3.1901e-02,  5.8324e-02],\n",
       "           [-4.8462e-02,  2.5315e-02,  5.0503e-02],\n",
       "           [-1.7872e-02, -8.7452e-03, -2.2658e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2053e-02,  1.8209e-02, -4.1428e-02],\n",
       "           [ 1.9010e-02,  4.2698e-04, -2.8953e-03],\n",
       "           [ 8.3032e-03,  9.5120e-03, -1.7215e-02]],\n",
       " \n",
       "          [[ 9.4271e-03,  9.2335e-03,  4.9002e-02],\n",
       "           [-3.6138e-02,  3.2985e-02, -4.9100e-02],\n",
       "           [-5.3220e-02, -6.2969e-03,  1.5349e-03]],\n",
       " \n",
       "          [[ 3.9058e-02, -1.3362e-02, -1.6745e-02],\n",
       "           [ 5.7270e-02,  3.0131e-03,  3.9916e-02],\n",
       "           [ 1.7462e-02, -4.9717e-02,  3.2592e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.9710e-02, -4.9039e-02,  4.2655e-02],\n",
       "           [ 4.6875e-02,  3.9579e-02, -4.2417e-02],\n",
       "           [-4.8229e-02, -1.5971e-02,  3.6017e-02]],\n",
       " \n",
       "          [[ 2.9743e-02,  3.2040e-02,  3.7630e-02],\n",
       "           [ 5.5453e-02, -5.1408e-02,  3.0008e-02],\n",
       "           [ 2.2306e-02,  2.3380e-02,  3.4339e-02]],\n",
       " \n",
       "          [[-5.6862e-02, -4.9748e-02, -5.6568e-03],\n",
       "           [-1.3163e-03,  5.5080e-02, -4.2632e-02],\n",
       "           [ 7.4843e-03,  3.7381e-02,  5.5207e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0361,  0.0061, -0.0306,  0.0394,  0.0567, -0.0557,  0.0412,  0.0398,\n",
       "          0.0493,  0.0483,  0.0326, -0.0341, -0.0186,  0.0189, -0.0081, -0.0187,\n",
       "          0.0127,  0.0161,  0.0475,  0.0556, -0.0375,  0.0140, -0.0005, -0.0488,\n",
       "         -0.0231,  0.0192, -0.0036,  0.0567, -0.0338,  0.0253, -0.0174, -0.0540],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0410, -0.0109, -0.0181],\n",
       "           [-0.0291,  0.0334, -0.0444],\n",
       "           [-0.0182,  0.0402,  0.0200]],\n",
       " \n",
       "          [[-0.0427,  0.0246, -0.0466],\n",
       "           [-0.0396, -0.0494,  0.0393],\n",
       "           [ 0.0357,  0.0058, -0.0046]],\n",
       " \n",
       "          [[-0.0287, -0.0465, -0.0119],\n",
       "           [-0.0247, -0.0464, -0.0408],\n",
       "           [-0.0417, -0.0411, -0.0566]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0281, -0.0114,  0.0494],\n",
       "           [ 0.0466,  0.0265,  0.0508],\n",
       "           [-0.0218, -0.0431, -0.0027]],\n",
       " \n",
       "          [[-0.0522,  0.0337,  0.0452],\n",
       "           [-0.0270, -0.0165, -0.0188],\n",
       "           [ 0.0383,  0.0471, -0.0033]],\n",
       " \n",
       "          [[ 0.0253,  0.0013,  0.0007],\n",
       "           [-0.0027,  0.0552, -0.0540],\n",
       "           [ 0.0469,  0.0515,  0.0162]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0071, -0.0228, -0.0134],\n",
       "           [ 0.0559,  0.0137, -0.0584],\n",
       "           [-0.0466, -0.0203, -0.0045]],\n",
       " \n",
       "          [[ 0.0311, -0.0084, -0.0169],\n",
       "           [ 0.0490,  0.0048,  0.0545],\n",
       "           [ 0.0474, -0.0387,  0.0546]],\n",
       " \n",
       "          [[-0.0270,  0.0394, -0.0358],\n",
       "           [-0.0017, -0.0079, -0.0547],\n",
       "           [ 0.0390,  0.0450,  0.0195]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0134,  0.0007,  0.0168],\n",
       "           [-0.0155, -0.0015,  0.0198],\n",
       "           [-0.0274, -0.0566,  0.0144]],\n",
       " \n",
       "          [[ 0.0413,  0.0060,  0.0219],\n",
       "           [ 0.0299, -0.0574, -0.0463],\n",
       "           [-0.0376,  0.0423,  0.0298]],\n",
       " \n",
       "          [[ 0.0574,  0.0095, -0.0080],\n",
       "           [-0.0110,  0.0496, -0.0551],\n",
       "           [ 0.0550, -0.0148,  0.0248]]],\n",
       " \n",
       " \n",
       "         [[[-0.0104, -0.0207,  0.0423],\n",
       "           [ 0.0569,  0.0393, -0.0493],\n",
       "           [-0.0063,  0.0272,  0.0158]],\n",
       " \n",
       "          [[-0.0114, -0.0028, -0.0057],\n",
       "           [-0.0342,  0.0322,  0.0275],\n",
       "           [ 0.0506,  0.0285,  0.0437]],\n",
       " \n",
       "          [[-0.0444, -0.0581, -0.0477],\n",
       "           [ 0.0481,  0.0257,  0.0568],\n",
       "           [ 0.0462,  0.0209, -0.0551]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0543,  0.0224,  0.0431],\n",
       "           [ 0.0188, -0.0121,  0.0552],\n",
       "           [ 0.0440,  0.0177, -0.0095]],\n",
       " \n",
       "          [[ 0.0268, -0.0510,  0.0009],\n",
       "           [-0.0237, -0.0143, -0.0406],\n",
       "           [-0.0190,  0.0418,  0.0571]],\n",
       " \n",
       "          [[ 0.0130,  0.0324,  0.0509],\n",
       "           [ 0.0413,  0.0017, -0.0509],\n",
       "           [-0.0291, -0.0200, -0.0395]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0281,  0.0287, -0.0084],\n",
       "           [-0.0044,  0.0580,  0.0234],\n",
       "           [ 0.0126, -0.0528,  0.0573]],\n",
       " \n",
       "          [[-0.0365,  0.0213,  0.0230],\n",
       "           [ 0.0211,  0.0331, -0.0343],\n",
       "           [-0.0167,  0.0203,  0.0553]],\n",
       " \n",
       "          [[ 0.0577,  0.0589, -0.0114],\n",
       "           [ 0.0057, -0.0052,  0.0192],\n",
       "           [ 0.0374, -0.0177, -0.0531]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0393, -0.0006, -0.0545],\n",
       "           [ 0.0164, -0.0507, -0.0167],\n",
       "           [ 0.0570,  0.0477,  0.0379]],\n",
       " \n",
       "          [[ 0.0516,  0.0536,  0.0480],\n",
       "           [ 0.0499, -0.0501, -0.0335],\n",
       "           [-0.0585,  0.0102,  0.0452]],\n",
       " \n",
       "          [[ 0.0089, -0.0346,  0.0582],\n",
       "           [-0.0146,  0.0509,  0.0109],\n",
       "           [-0.0338, -0.0259, -0.0316]]],\n",
       " \n",
       " \n",
       "         [[[-0.0008, -0.0180,  0.0447],\n",
       "           [-0.0227,  0.0528, -0.0016],\n",
       "           [-0.0248,  0.0549,  0.0574]],\n",
       " \n",
       "          [[ 0.0070,  0.0348,  0.0359],\n",
       "           [ 0.0249,  0.0210, -0.0433],\n",
       "           [-0.0551,  0.0559,  0.0039]],\n",
       " \n",
       "          [[ 0.0119, -0.0504,  0.0206],\n",
       "           [ 0.0333,  0.0231,  0.0119],\n",
       "           [ 0.0028, -0.0397,  0.0166]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0246,  0.0404,  0.0524],\n",
       "           [-0.0499, -0.0316, -0.0045],\n",
       "           [-0.0017,  0.0358, -0.0318]],\n",
       " \n",
       "          [[ 0.0035, -0.0080,  0.0261],\n",
       "           [-0.0096,  0.0271,  0.0234],\n",
       "           [-0.0319,  0.0147,  0.0270]],\n",
       " \n",
       "          [[ 0.0334, -0.0369,  0.0313],\n",
       "           [ 0.0097,  0.0322,  0.0424],\n",
       "           [-0.0056,  0.0160,  0.0326]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0546,  0.0459, -0.0126],\n",
       "           [-0.0466, -0.0290,  0.0041],\n",
       "           [ 0.0442,  0.0471, -0.0028]],\n",
       " \n",
       "          [[ 0.0149,  0.0571,  0.0069],\n",
       "           [ 0.0560, -0.0508,  0.0515],\n",
       "           [-0.0352, -0.0200,  0.0360]],\n",
       " \n",
       "          [[-0.0241,  0.0346, -0.0424],\n",
       "           [ 0.0532,  0.0534, -0.0018],\n",
       "           [ 0.0305,  0.0237,  0.0040]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0180,  0.0087, -0.0212],\n",
       "           [ 0.0248, -0.0515,  0.0575],\n",
       "           [-0.0182, -0.0298,  0.0037]],\n",
       " \n",
       "          [[ 0.0318,  0.0028,  0.0038],\n",
       "           [-0.0192, -0.0314, -0.0564],\n",
       "           [-0.0263,  0.0292,  0.0214]],\n",
       " \n",
       "          [[ 0.0531, -0.0031,  0.0135],\n",
       "           [-0.0105, -0.0222,  0.0241],\n",
       "           [ 0.0079,  0.0134, -0.0029]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0324,  0.0355, -0.0375,  0.0237,  0.0492, -0.0275,  0.0480, -0.0399,\n",
       "          0.0279,  0.0202, -0.0306, -0.0216,  0.0432, -0.0015,  0.0303, -0.0542,\n",
       "         -0.0405,  0.0383,  0.0306, -0.0344,  0.0306,  0.0539,  0.0215,  0.0260,\n",
       "         -0.0067, -0.0109,  0.0226,  0.0368, -0.0084,  0.0471,  0.0098, -0.0155,\n",
       "          0.0531,  0.0525, -0.0333,  0.0467,  0.0075, -0.0374,  0.0085, -0.0346,\n",
       "          0.0083, -0.0573,  0.0446,  0.0436,  0.0171, -0.0003, -0.0276,  0.0458,\n",
       "         -0.0563, -0.0311, -0.0507, -0.0474, -0.0405,  0.0087,  0.0369, -0.0368,\n",
       "          0.0227,  0.0280, -0.0585,  0.0214, -0.0141, -0.0321,  0.0324, -0.0575],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 1.8248e-02,  1.5165e-02, -3.8172e-02],\n",
       "           [ 2.8658e-02,  2.2644e-02, -9.0803e-03],\n",
       "           [ 2.1384e-02,  1.9148e-02, -1.0859e-02]],\n",
       " \n",
       "          [[ 7.2606e-03,  2.0637e-02,  1.0506e-03],\n",
       "           [ 2.5391e-02, -9.5505e-03,  9.6918e-03],\n",
       "           [-2.7544e-02,  3.4982e-02,  7.1274e-04]],\n",
       " \n",
       "          [[-3.8189e-02,  9.1398e-03,  3.9690e-02],\n",
       "           [ 1.0300e-02,  3.2551e-02, -3.2688e-03],\n",
       "           [ 1.5365e-02,  2.5431e-02,  2.8079e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.7534e-02, -1.1455e-02,  1.1907e-02],\n",
       "           [ 2.7501e-02,  2.7067e-02, -2.1754e-02],\n",
       "           [ 4.1111e-02,  2.5005e-02,  2.6208e-02]],\n",
       " \n",
       "          [[ 2.5660e-02, -2.2212e-02,  3.0366e-02],\n",
       "           [ 9.7025e-03,  3.7354e-02, -3.7669e-03],\n",
       "           [ 2.7615e-03,  3.4685e-02,  1.4665e-02]],\n",
       " \n",
       "          [[ 4.0796e-02, -1.0812e-03,  3.6487e-02],\n",
       "           [ 4.1131e-02, -3.8353e-02, -2.1953e-02],\n",
       "           [-3.6401e-02,  1.9004e-02,  3.7766e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2759e-02, -6.0686e-03,  3.9093e-02],\n",
       "           [ 3.0869e-02,  3.7779e-02, -1.8162e-02],\n",
       "           [-3.2238e-02, -1.5014e-02, -3.8817e-02]],\n",
       " \n",
       "          [[-9.8980e-03, -3.8270e-02, -1.8955e-02],\n",
       "           [-3.5810e-02, -3.8208e-02,  2.5228e-02],\n",
       "           [-9.0441e-03, -1.5218e-02,  3.2514e-02]],\n",
       " \n",
       "          [[-9.4828e-03,  2.3979e-02, -1.6083e-02],\n",
       "           [-1.3550e-02, -2.9501e-02, -4.0399e-02],\n",
       "           [-3.0089e-02, -3.6745e-02, -2.9555e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.0210e-03,  2.5005e-02, -3.8287e-02],\n",
       "           [ 3.9015e-02,  1.9614e-02,  2.6126e-03],\n",
       "           [-1.1600e-02, -3.9457e-02,  2.6290e-02]],\n",
       " \n",
       "          [[ 1.6402e-02, -1.2309e-02,  2.9942e-02],\n",
       "           [-4.0120e-02,  3.9106e-02,  3.9789e-02],\n",
       "           [-2.0204e-02,  8.6748e-03,  6.2248e-03]],\n",
       " \n",
       "          [[-3.6524e-02,  2.5201e-03,  2.6846e-02],\n",
       "           [-3.3075e-02, -7.2667e-03,  2.9987e-02],\n",
       "           [-2.1363e-02, -1.7187e-02, -4.0127e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.4719e-03,  2.4046e-02,  1.2425e-02],\n",
       "           [-1.7413e-02, -7.4680e-03, -2.0656e-03],\n",
       "           [ 2.6682e-02, -5.3000e-03, -2.2421e-02]],\n",
       " \n",
       "          [[ 3.3620e-03,  1.3925e-02, -1.4263e-02],\n",
       "           [ 1.7734e-02, -6.6857e-03,  2.0700e-02],\n",
       "           [-3.2477e-02, -3.6159e-02,  1.1676e-02]],\n",
       " \n",
       "          [[-4.1059e-02,  1.2728e-02, -2.8321e-02],\n",
       "           [-3.4276e-02, -3.6479e-02,  2.0574e-02],\n",
       "           [-5.0491e-03,  1.1368e-02,  1.9594e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9907e-02,  4.1318e-02,  1.6033e-02],\n",
       "           [ 1.6013e-03,  1.2461e-02,  1.8977e-03],\n",
       "           [-3.3152e-02, -1.4838e-02,  3.8103e-02]],\n",
       " \n",
       "          [[-1.4363e-02,  3.6263e-02, -3.1485e-02],\n",
       "           [-3.3955e-02, -6.1855e-03,  2.3716e-02],\n",
       "           [-1.8919e-04,  1.9680e-02, -1.9454e-02]],\n",
       " \n",
       "          [[-3.6092e-02,  3.4566e-02,  9.0186e-03],\n",
       "           [ 3.9534e-02, -4.1473e-02,  4.0227e-02],\n",
       "           [ 1.0335e-02,  3.8817e-02,  2.8648e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.5407e-02,  3.9353e-02, -2.5208e-02],\n",
       "           [ 2.2587e-02,  1.0451e-02, -2.0977e-02],\n",
       "           [ 3.5389e-02, -3.5139e-03, -6.1491e-03]],\n",
       " \n",
       "          [[ 2.8083e-03,  4.0095e-02,  7.2427e-03],\n",
       "           [-4.0648e-02, -4.1106e-02, -3.6785e-02],\n",
       "           [-3.1699e-02, -8.2133e-03, -3.9498e-02]],\n",
       " \n",
       "          [[ 1.8830e-03,  6.7211e-03,  2.1623e-02],\n",
       "           [ 2.6856e-02,  2.0147e-02,  6.5479e-03],\n",
       "           [ 4.1074e-02,  3.6912e-02, -7.4916e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.0407e-02, -1.7698e-02, -2.0306e-02],\n",
       "           [-3.8579e-02,  2.7991e-02, -1.8524e-02],\n",
       "           [ 2.1765e-02,  2.5099e-02,  1.8915e-02]],\n",
       " \n",
       "          [[-2.5098e-02, -1.1183e-02, -2.9049e-02],\n",
       "           [ 3.9471e-02, -3.8607e-02,  2.0495e-02],\n",
       "           [ 3.6130e-02,  3.5948e-02,  2.9235e-02]],\n",
       " \n",
       "          [[-3.5572e-02, -3.4437e-02,  1.9836e-02],\n",
       "           [-3.6081e-02, -3.5191e-02,  3.9817e-04],\n",
       "           [-3.4380e-02,  2.6968e-02,  4.0682e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.1012e-02, -5.6972e-03,  3.8290e-02],\n",
       "           [-3.5294e-02, -6.9845e-03, -2.8683e-02],\n",
       "           [ 4.2949e-03,  3.4419e-02, -4.8159e-03]],\n",
       " \n",
       "          [[-1.7777e-03, -3.1504e-02, -2.2992e-02],\n",
       "           [ 2.9053e-02, -2.6037e-02,  2.6589e-02],\n",
       "           [ 2.6211e-02, -1.9045e-02, -3.1349e-02]],\n",
       " \n",
       "          [[ 3.1020e-02,  6.4486e-03,  2.1387e-03],\n",
       "           [-3.3408e-02,  1.3485e-02,  1.3609e-02],\n",
       "           [-1.5920e-02,  1.7901e-02,  6.5796e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.5362e-03, -9.2365e-03, -1.7963e-02],\n",
       "           [-2.0704e-02, -3.8643e-02,  3.2879e-02],\n",
       "           [ 2.0177e-02,  1.6806e-02, -4.6522e-03]],\n",
       " \n",
       "          [[ 2.0431e-02,  1.6708e-02,  2.8553e-02],\n",
       "           [ 4.1628e-02, -1.2977e-02, -1.3715e-02],\n",
       "           [ 4.0195e-02,  3.7920e-02, -2.3263e-02]],\n",
       " \n",
       "          [[ 3.7404e-02,  2.1705e-03,  3.8420e-02],\n",
       "           [ 3.5070e-02,  4.0938e-02, -1.9067e-02],\n",
       "           [-2.9036e-02, -3.4947e-02, -1.6991e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.9041e-02,  2.7998e-02, -9.5615e-03],\n",
       "           [-2.8894e-02,  1.0335e-02, -3.5595e-02],\n",
       "           [ 1.1547e-02, -3.1081e-02, -6.0036e-03]],\n",
       " \n",
       "          [[ 3.6499e-02,  3.9588e-02, -2.4375e-02],\n",
       "           [ 2.6754e-02,  1.8312e-02,  2.1407e-02],\n",
       "           [-1.7087e-02,  8.7931e-03,  1.6466e-02]],\n",
       " \n",
       "          [[-3.7838e-03,  1.0534e-02, -3.8016e-02],\n",
       "           [ 3.5973e-02, -9.2874e-05, -1.5238e-02],\n",
       "           [ 8.3104e-03, -2.2489e-02,  2.0593e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0563e-02,  2.9145e-02, -3.2681e-02],\n",
       "           [-2.2399e-02,  2.9609e-02,  1.7364e-02],\n",
       "           [ 2.6407e-02, -1.2184e-02,  3.4410e-02]],\n",
       " \n",
       "          [[-1.5768e-02, -2.6883e-02,  5.2440e-03],\n",
       "           [ 2.4819e-02,  1.1635e-03, -2.7927e-02],\n",
       "           [ 2.5868e-02,  2.1520e-02,  2.3112e-02]],\n",
       " \n",
       "          [[ 4.0627e-02, -1.9090e-03,  1.2399e-02],\n",
       "           [-3.7184e-02, -2.1631e-02, -2.1855e-02],\n",
       "           [-1.5857e-02, -3.5793e-02,  3.4766e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0408,  0.0392,  0.0050,  0.0059, -0.0182, -0.0098, -0.0372, -0.0265,\n",
       "          0.0013, -0.0337,  0.0383,  0.0212, -0.0266, -0.0246,  0.0060,  0.0132,\n",
       "          0.0353,  0.0370, -0.0248,  0.0108,  0.0128,  0.0085, -0.0107,  0.0201,\n",
       "          0.0120,  0.0163, -0.0128, -0.0305,  0.0337, -0.0276,  0.0077, -0.0332,\n",
       "          0.0234, -0.0025, -0.0190, -0.0065, -0.0309,  0.0291, -0.0226, -0.0038,\n",
       "          0.0293, -0.0107,  0.0399,  0.0035,  0.0385,  0.0388, -0.0336, -0.0246,\n",
       "         -0.0198,  0.0259, -0.0126,  0.0317,  0.0174, -0.0183, -0.0110,  0.0202,\n",
       "         -0.0094,  0.0045, -0.0343, -0.0233,  0.0113, -0.0366, -0.0068, -0.0357],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0619]],\n",
       " \n",
       "          [[-0.0945]],\n",
       " \n",
       "          [[ 0.0803]],\n",
       " \n",
       "          [[-0.0909]],\n",
       " \n",
       "          [[-0.0533]],\n",
       " \n",
       "          [[ 0.0882]],\n",
       " \n",
       "          [[-0.0287]],\n",
       " \n",
       "          [[-0.0305]],\n",
       " \n",
       "          [[-0.0026]],\n",
       " \n",
       "          [[-0.0768]],\n",
       " \n",
       "          [[-0.0636]],\n",
       " \n",
       "          [[ 0.0844]],\n",
       " \n",
       "          [[ 0.0919]],\n",
       " \n",
       "          [[ 0.1228]],\n",
       " \n",
       "          [[-0.0964]],\n",
       " \n",
       "          [[-0.0202]],\n",
       " \n",
       "          [[-0.0552]],\n",
       " \n",
       "          [[-0.0681]],\n",
       " \n",
       "          [[-0.0721]],\n",
       " \n",
       "          [[ 0.0742]],\n",
       " \n",
       "          [[ 0.0607]],\n",
       " \n",
       "          [[ 0.0663]],\n",
       " \n",
       "          [[-0.0843]],\n",
       " \n",
       "          [[ 0.0482]],\n",
       " \n",
       "          [[-0.0593]],\n",
       " \n",
       "          [[ 0.0532]],\n",
       " \n",
       "          [[-0.0944]],\n",
       " \n",
       "          [[ 0.0765]],\n",
       " \n",
       "          [[ 0.0140]],\n",
       " \n",
       "          [[ 0.1138]],\n",
       " \n",
       "          [[-0.0836]],\n",
       " \n",
       "          [[ 0.0762]],\n",
       " \n",
       "          [[ 0.0062]],\n",
       " \n",
       "          [[ 0.0341]],\n",
       " \n",
       "          [[-0.0910]],\n",
       " \n",
       "          [[-0.0387]],\n",
       " \n",
       "          [[-0.1232]],\n",
       " \n",
       "          [[-0.1123]],\n",
       " \n",
       "          [[ 0.0879]],\n",
       " \n",
       "          [[-0.0968]],\n",
       " \n",
       "          [[-0.0712]],\n",
       " \n",
       "          [[-0.0448]],\n",
       " \n",
       "          [[ 0.0305]],\n",
       " \n",
       "          [[ 0.0960]],\n",
       " \n",
       "          [[ 0.0416]],\n",
       " \n",
       "          [[-0.0733]],\n",
       " \n",
       "          [[ 0.1173]],\n",
       " \n",
       "          [[-0.0026]],\n",
       " \n",
       "          [[ 0.1063]],\n",
       " \n",
       "          [[-0.0007]],\n",
       " \n",
       "          [[ 0.1138]],\n",
       " \n",
       "          [[ 0.0976]],\n",
       " \n",
       "          [[ 0.0870]],\n",
       " \n",
       "          [[-0.1237]],\n",
       " \n",
       "          [[ 0.0964]],\n",
       " \n",
       "          [[ 0.0698]],\n",
       " \n",
       "          [[ 0.0808]],\n",
       " \n",
       "          [[-0.0670]],\n",
       " \n",
       "          [[ 0.0277]],\n",
       " \n",
       "          [[-0.0231]],\n",
       " \n",
       "          [[ 0.1226]],\n",
       " \n",
       "          [[ 0.1186]],\n",
       " \n",
       "          [[-0.0428]],\n",
       " \n",
       "          [[ 0.0012]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1068]],\n",
       " \n",
       "          [[ 0.0689]],\n",
       " \n",
       "          [[-0.0451]],\n",
       " \n",
       "          [[-0.0229]],\n",
       " \n",
       "          [[-0.0849]],\n",
       " \n",
       "          [[-0.0498]],\n",
       " \n",
       "          [[ 0.0522]],\n",
       " \n",
       "          [[-0.0044]],\n",
       " \n",
       "          [[-0.0930]],\n",
       " \n",
       "          [[ 0.1195]],\n",
       " \n",
       "          [[ 0.1129]],\n",
       " \n",
       "          [[-0.0715]],\n",
       " \n",
       "          [[-0.1247]],\n",
       " \n",
       "          [[ 0.0230]],\n",
       " \n",
       "          [[-0.0966]],\n",
       " \n",
       "          [[ 0.0970]],\n",
       " \n",
       "          [[-0.0154]],\n",
       " \n",
       "          [[ 0.1079]],\n",
       " \n",
       "          [[ 0.0254]],\n",
       " \n",
       "          [[ 0.0365]],\n",
       " \n",
       "          [[ 0.0981]],\n",
       " \n",
       "          [[ 0.1096]],\n",
       " \n",
       "          [[ 0.0757]],\n",
       " \n",
       "          [[ 0.0105]],\n",
       " \n",
       "          [[ 0.0466]],\n",
       " \n",
       "          [[-0.0235]],\n",
       " \n",
       "          [[-0.0692]],\n",
       " \n",
       "          [[-0.0211]],\n",
       " \n",
       "          [[ 0.1239]],\n",
       " \n",
       "          [[-0.1226]],\n",
       " \n",
       "          [[-0.1028]],\n",
       " \n",
       "          [[ 0.0697]],\n",
       " \n",
       "          [[ 0.0336]],\n",
       " \n",
       "          [[-0.0623]],\n",
       " \n",
       "          [[-0.0366]],\n",
       " \n",
       "          [[-0.0036]],\n",
       " \n",
       "          [[-0.0044]],\n",
       " \n",
       "          [[-0.0435]],\n",
       " \n",
       "          [[-0.1176]],\n",
       " \n",
       "          [[-0.1224]],\n",
       " \n",
       "          [[-0.0804]],\n",
       " \n",
       "          [[-0.0690]],\n",
       " \n",
       "          [[-0.0695]],\n",
       " \n",
       "          [[-0.1046]],\n",
       " \n",
       "          [[ 0.0457]],\n",
       " \n",
       "          [[ 0.0583]],\n",
       " \n",
       "          [[ 0.1247]],\n",
       " \n",
       "          [[ 0.0868]],\n",
       " \n",
       "          [[-0.0261]],\n",
       " \n",
       "          [[ 0.0473]],\n",
       " \n",
       "          [[ 0.1242]],\n",
       " \n",
       "          [[ 0.1152]],\n",
       " \n",
       "          [[ 0.0873]],\n",
       " \n",
       "          [[-0.1050]],\n",
       " \n",
       "          [[-0.0653]],\n",
       " \n",
       "          [[ 0.0495]],\n",
       " \n",
       "          [[ 0.0960]],\n",
       " \n",
       "          [[ 0.0066]],\n",
       " \n",
       "          [[ 0.0707]],\n",
       " \n",
       "          [[ 0.0930]],\n",
       " \n",
       "          [[-0.0122]],\n",
       " \n",
       "          [[ 0.1096]],\n",
       " \n",
       "          [[-0.0064]],\n",
       " \n",
       "          [[-0.0200]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0739, -0.0326], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0129, -0.0305, -0.0577,  ..., -0.0037,  0.0358, -0.0811],\n",
       "         [ 0.0433,  0.0669, -0.0880,  ...,  0.0442,  0.0264,  0.0710],\n",
       "         [ 0.0168, -0.0377,  0.0531,  ..., -0.0676, -0.0820,  0.0402],\n",
       "         ...,\n",
       "         [-0.0147, -0.0413, -0.0520,  ...,  0.0114, -0.0157, -0.0019],\n",
       "         [ 0.0858, -0.0291, -0.0833,  ..., -0.0620,  0.0110,  0.0646],\n",
       "         [-0.0844,  0.0281,  0.0826,  ...,  0.0334, -0.0423,  0.0100]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0548, -0.0235,  0.0541,  0.0813, -0.0255, -0.0788,  0.0826,  0.0459,\n",
       "         -0.0332, -0.0143], requires_grad=True)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "list(utils.SmallCNN().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "756dcbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1/25 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "Training Client 2/5\n",
      "Training Client 3/5\n",
      "Training Client 4/5\n",
      "Training Client 5/5\n",
      "Training Server\n",
      "Evaluate on round 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSAM  | Test Loss: 2.3046, Test Acc: 10.00%\n",
      "\n",
      "--- Round 2/25 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Client 2/5\n",
      "Training Client 3/5\n",
      "Training Client 4/5\n",
      "Training Client 5/5\n",
      "Training Server\n",
      "Evaluate on round 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSAM  | Test Loss: 2.3046, Test Acc: 10.00%\n",
      "\n",
      "--- Round 3/25 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Client 2/5\n",
      "Training Client 3/5\n",
      "Training Client 4/5\n",
      "Training Client 5/5\n",
      "Training Server\n",
      "Evaluate on round 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSAM  | Test Loss: 2.3046, Test Acc: 10.00%\n",
      "\n",
      "--- Round 4/25 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Client 2/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_164/1791096084.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kaggle/working/ATML-PA-4/fed_lib/fed_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, rounds, lr, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Clients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_client_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Server\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ATML-PA-4/fed_lib/fed_methods.py\u001b[0m in \u001b[0;36mexec_client_round\u001b[0;34m(self, server, clients, client_dataloaders, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mclient_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ATML-PA-4/fed_lib/fed_methods.py\u001b[0m in \u001b[0;36m_train_client\u001b[0;34m(self, local_model, local_dataloader, criterion, device, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mmodel_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradients_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mlocal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_model_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ATML-PA-4/fed_lib/fed_methods.py\u001b[0m in \u001b[0;36mcalculate_gradients_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     new_grads.append(\n\u001b[0;32m--> 220\u001b[0;31m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     )\n\u001b[1;32m    222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fed.train(25, lr=1e-3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58e33a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallCNN(\n",
       "  (backbone): Sequential(\n",
       "    (0): SmallConvBlock(in_channels=3, out_channels=32)\n",
       "    (1): SmallConvBlock(in_channels=32, out_channels=64)\n",
       "    (2): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (task_head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed.clients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c375f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
