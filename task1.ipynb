{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca61c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ATML-PA-4'...\n",
      "warning: redirecting to https://github.com/Zapy67/ATML-PA-4/\n",
      "remote: Enumerating objects: 47, done.\u001b[K\n",
      "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 47 (delta 20), reused 38 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (47/47), 289.00 KiB | 10.32 MiB/s, done.\n",
      "Resolving deltas: 100% (20/20), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone http://github.com/Zapy67/ATML-PA-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05d7bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: redirecting to https://github.com/Zapy67/ATML-PA-4/\n",
      "From http://github.com/Zapy67/ATML-PA-4\n",
      " * branch            HEAD       -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull http://github.com/Zapy67/ATML-PA-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3c8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ATML-PA-4\n"
     ]
    }
   ],
   "source": [
    "%cd ATML-PA-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694884d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ATML - PA 4.pdf'   fed_lib   README.md     task2.ipynb   task4.ipynb\n",
      " data\t\t    LICENSE   task1.ipynb   task3.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0fb85",
   "metadata": {},
   "source": [
    "#  FedSGD vs Centralized SGD (Theoretical Equivalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea379c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b40bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fed_lib' from '/kaggle/working/ATML-PA-4/fed_lib/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fed_lib\n",
    "import importlib\n",
    "importlib.reload(fed_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849d54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fed_lib import fed_methods, fed_model, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1923ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0012ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_weights = [0.2] * 5\n",
    "domains = [0.2] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2312eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed = fed_model.Federation(5, fed_methods.FedSGD(client_weights=client_weights), domains, device, batch_size=64, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b5745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.3946, grad_norm=1.2384\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.3942, grad_norm=1.2241\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.3930, grad_norm=1.2459\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.3970, grad_norm=1.2257\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.3941, grad_norm=1.2402\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 1.2341\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 1.2404\n",
      "Evaluate on round 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2977, Test Acc: 13.51%\n",
      "Central | Test Loss: 2.2949, Test Acc: 13.89%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                9.030587e-04 1.950293e-04\n",
      "task_head.1.weight                       4.546794e-04 2.548755e-04\n",
      "backbone.0.block.0.weight                3.032935e-04 9.326791e-05\n",
      "backbone.1.block.1.weight                3.680407e-05 4.601135e-06\n",
      "backbone.0.block.1.weight                2.769596e-05 4.896001e-06\n",
      "Overall Statistics:\n",
      "Total L2 difference:        1.057027e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 2/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.3282, grad_norm=0.9310\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.3287, grad_norm=0.9300\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.3294, grad_norm=0.9437\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.3312, grad_norm=0.9266\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.3278, grad_norm=0.9338\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.9320\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.9358\n",
      "Evaluate on round 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2916, Test Acc: 11.93%\n",
      "Central | Test Loss: 2.2711, Test Acc: 16.62%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                1.371722e-03 2.962389e-04\n",
      "task_head.1.weight                       6.550957e-04 3.675720e-04\n",
      "backbone.0.block.0.weight                5.082266e-04 1.562878e-04\n",
      "backbone.1.block.1.weight                5.033982e-05 6.293697e-06\n",
      "backbone.0.block.1.weight                4.295820e-05 7.594009e-06\n",
      "Overall Statistics:\n",
      "Total L2 difference:        1.604774e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 3/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.2897, grad_norm=0.7655\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.2920, grad_norm=0.7551\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.2885, grad_norm=0.7733\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.2930, grad_norm=0.7528\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.2882, grad_norm=0.7638\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.7609\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.7646\n",
      "Evaluate on round 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2868, Test Acc: 11.49%\n",
      "Central | Test Loss: 2.2542, Test Acc: 17.36%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                1.758282e-03 3.797155e-04\n",
      "task_head.1.weight                       8.107751e-04 4.550107e-04\n",
      "backbone.0.block.0.weight                5.735736e-04 1.763827e-04\n",
      "backbone.1.block.1.weight                6.239479e-05 7.800983e-06\n",
      "backbone.0.block.1.weight                5.811065e-05 1.027261e-05\n",
      "Overall Statistics:\n",
      "Total L2 difference:        2.022172e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 4/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client 1: samples=10000.0, loss=2.2626, grad_norm=0.6492\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.2647, grad_norm=0.6405\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.2619, grad_norm=0.6630\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.2665, grad_norm=0.6358\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.2621, grad_norm=0.6505\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.6463\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.6514\n",
      "Evaluate on round 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2828, Test Acc: 12.02%\n",
      "Central | Test Loss: 2.2396, Test Acc: 18.12%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                2.132383e-03 4.605002e-04\n",
      "task_head.1.weight                       9.934373e-04 5.573608e-04\n",
      "backbone.0.block.0.weight                7.598008e-04 2.336500e-04\n",
      "backbone.1.block.1.weight                7.418365e-05 9.274802e-06\n",
      "backbone.0.block.1.weight                7.322631e-05 1.294471e-05\n",
      "Overall Statistics:\n",
      "Total L2 difference:        2.475654e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 5/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.2440, grad_norm=0.5738\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.2441, grad_norm=0.5608\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.2413, grad_norm=0.5849\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.2468, grad_norm=0.5613\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.2420, grad_norm=0.5721\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.5691\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.5716\n",
      "Evaluate on round 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2793, Test Acc: 13.05%\n",
      "Central | Test Loss: 2.2268, Test Acc: 18.68%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                2.440301e-03 5.269913e-04\n",
      "task_head.1.weight                       1.128021e-03 6.324810e-04\n",
      "backbone.0.block.0.weight                8.489923e-04 2.610772e-04\n",
      "backbone.1.block.1.weight                8.684442e-05 1.085741e-05\n",
      "backbone.0.block.1.weight                8.044858e-05 1.422144e-05\n",
      "Overall Statistics:\n",
      "Total L2 difference:        2.823530e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 6/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client 1: samples=10000.0, loss=2.2287, grad_norm=0.5158\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.2304, grad_norm=0.5045\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.2257, grad_norm=0.5267\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.2310, grad_norm=0.5085\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.2269, grad_norm=0.5176\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.5129\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.5190\n",
      "Evaluate on round 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2763, Test Acc: 13.72%\n",
      "Central | Test Loss: 2.2146, Test Acc: 18.79%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                2.725983e-03 5.886802e-04\n",
      "task_head.1.weight                       1.236553e-03 6.927603e-04\n",
      "backbone.0.block.0.weight                9.773707e-04 3.005547e-04\n",
      "backbone.1.block.1.weight                9.735008e-05 1.217036e-05\n",
      "backbone.0.block.1.weight                9.235522e-05 1.632625e-05\n",
      "Overall Statistics:\n",
      "Total L2 difference:        3.154076e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 7/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client 1: samples=10000.0, loss=2.2152, grad_norm=0.4755\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.2175, grad_norm=0.4611\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.2124, grad_norm=0.4883\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.2214, grad_norm=0.4645\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.2136, grad_norm=0.4725\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.4706\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.4755\n",
      "Evaluate on round 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2735, Test Acc: 14.08%\n",
      "Central | Test Loss: 2.2057, Test Acc: 18.90%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                3.034657e-03 6.553334e-04\n",
      "task_head.1.weight                       1.370374e-03 7.669743e-04\n",
      "backbone.0.block.0.weight                1.103226e-03 3.392563e-04\n",
      "backbone.1.block.1.weight                1.100719e-04 1.376014e-05\n",
      "task_head.1.bias                         9.317463e-05 5.754019e-04\n",
      "Overall Statistics:\n",
      "Total L2 difference:        3.513395e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 8/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.2032, grad_norm=0.4480\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.2064, grad_norm=0.4401\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.2017, grad_norm=0.4565\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.2085, grad_norm=0.4330\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.2045, grad_norm=0.4435\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.4424\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.4489\n",
      "Evaluate on round 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2710, Test Acc: 14.14%\n",
      "Central | Test Loss: 2.1962, Test Acc: 19.70%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                3.331959e-03 7.195305e-04\n",
      "task_head.1.weight                       1.520337e-03 8.499603e-04\n",
      "backbone.0.block.0.weight                1.220234e-03 3.752368e-04\n",
      "backbone.1.block.1.weight                1.245557e-04 1.556992e-05\n",
      "task_head.1.bias                         1.089521e-04 6.730216e-04\n",
      "Overall Statistics:\n",
      "Total L2 difference:        3.867068e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 9/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.1961, grad_norm=0.4266\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.1979, grad_norm=0.4141\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.1934, grad_norm=0.4319\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.1996, grad_norm=0.4194\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.1936, grad_norm=0.4210\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.4207\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.4271\n",
      "Evaluate on round 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2687, Test Acc: 13.94%\n",
      "Central | Test Loss: 2.1878, Test Acc: 19.86%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                3.622972e-03 7.823692e-04\n",
      "task_head.1.weight                       1.655796e-03 9.245864e-04\n",
      "backbone.0.block.0.weight                1.316253e-03 4.047629e-04\n",
      "backbone.1.block.1.weight                1.464810e-04 1.830958e-05\n",
      "task_head.1.bias                         1.255558e-04 7.755417e-04\n",
      "Overall Statistics:\n",
      "Total L2 difference:        4.203241e-03\n",
      "Total parameters:           20,234\n",
      "\n",
      "--- Round 10/10 ---\n",
      "Training Clients\n",
      "Training Client 1/5\n",
      "  Client 1: samples=10000.0, loss=2.1855, grad_norm=0.4100\n",
      "Training Client 2/5\n",
      "  Client 2: samples=10000.0, loss=2.1892, grad_norm=0.3975\n",
      "Training Client 3/5\n",
      "  Client 3: samples=10000.0, loss=2.1830, grad_norm=0.4182\n",
      "Training Client 4/5\n",
      "  Client 4: samples=10000.0, loss=2.1896, grad_norm=0.4020\n",
      "Training Client 5/5\n",
      "  Client 5: samples=10000.0, loss=2.1885, grad_norm=0.4038\n",
      "Training Server\n",
      "Applying FedSGD on Server\n",
      "Aggregating 5 clients with weights: ['0.200', '0.200', '0.200', '0.200', '0.200']\n",
      "Aggregated server grad_norm: 0.4043\n",
      "Training Central\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central avg grad norm: 0.4092\n",
      "Evaluate on round 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2665, Test Acc: 13.72%\n",
      "Central | Test Loss: 2.1813, Test Acc: 19.60%\n",
      "Comparing Server vs Central\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "backbone.1.block.0.weight                3.853226e-03 8.320868e-04\n",
      "task_head.1.weight                       1.756052e-03 9.793214e-04\n",
      "backbone.0.block.0.weight                1.462893e-03 4.498549e-04\n",
      "backbone.1.block.1.weight                1.626805e-04 2.033318e-05\n",
      "task_head.1.bias                         1.457978e-04 9.002758e-04\n",
      "Overall Statistics:\n",
      "Total L2 difference:        4.489321e-03\n",
      "Total parameters:           20,234\n",
      "Training Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedSGD  | Test Loss: 2.2665, Test Acc: 13.72%\n",
      "Central | Test Loss: 2.1813, Test Acc: 19.60%\n",
      "\n",
      "======================================================================\n",
      "Comparing Server vs Central\n",
      "======================================================================\n",
      "\n",
      "Top 5 layers with largest L2 differences:\n",
      "----------------------------------------------------------------------\n",
      "Layer                                         L2 Diff     Rel Diff\n",
      "----------------------------------------------------------------------\n",
      "backbone.1.block.0.weight                3.853226e-03 8.320868e-04\n",
      "task_head.1.weight                       1.756052e-03 9.793214e-04\n",
      "backbone.0.block.0.weight                1.462893e-03 4.498549e-04\n",
      "backbone.1.block.1.weight                1.626805e-04 2.033318e-05\n",
      "task_head.1.bias                         1.457978e-04 9.002758e-04\n",
      "\n",
      "======================================================================\n",
      "Overall Statistics:\n",
      "======================================================================\n",
      "Total L2 difference:        4.489321e-03\n",
      "Total L-inf difference:     3.315918e-04\n",
      "Avg relative difference:    2.824504e-03\n",
      "Total parameters:           20,234\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "fed.train(10, lr=0.05, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fef9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
